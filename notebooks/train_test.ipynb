{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))\n",
    "from src.face_recognition.pipelines.data_science.face_recognition import preprocessing, FaceFeaturesExtractor, FaceRecogniser, evaluate\n",
    "import tqdm\n",
    "import joblib\n",
    "from torchvision import transforms, datasets\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_to_embeddings(dataset, features_extractor):\n",
    "    transform = transforms.Compose([\n",
    "        preprocessing.ExifOrientationNormalize(),\n",
    "        transforms.Resize(1024)\n",
    "    ])\n",
    "\n",
    "    embeddings = []\n",
    "    labels = []\n",
    "    for img_path, label in tqdm.tqdm(dataset.samples):\n",
    "        _, embedding = features_extractor(transform(Image.open(img_path).convert('RGB')))\n",
    "        if embedding is None:\n",
    "            continue\n",
    "        if embedding.shape[0] > 1:\n",
    "            embedding = embedding[0, :]\n",
    "        embeddings.append(embedding.flatten())\n",
    "        labels.append(label)\n",
    "\n",
    "    return np.stack(embeddings), labels\n",
    "\n",
    "\n",
    "\n",
    "def normalise_string(string):\n",
    "    return string.lower().replace(' ', '_')\n",
    "\n",
    "def normalise_dict_keys(dictionary):\n",
    "    new_dict = dict()\n",
    "    for key in dictionary.keys():\n",
    "        new_dict[normalise_string(key)] = dictionary[key]\n",
    "    return new_dict\n",
    "\n",
    "\n",
    "def prepare_embeddings(train_path: str, augmented_train_path: str, augment: bool):\n",
    "    print(\"generating embeddings...\")\n",
    "    features_extractor = FaceFeaturesExtractor()\n",
    "\n",
    "    # use augmented dataset if augment is True\n",
    "    data_path = augmented_train_path if augment else train_path\n",
    "    dataset = datasets.ImageFolder(data_path)\n",
    "\n",
    "    # extract embeddings\n",
    "    embeddings, labels = dataset_to_embeddings(dataset, features_extractor)\n",
    "    print(embeddings.shape, len(labels))\n",
    "    # normalise labels\n",
    "    dataset.class_to_idx = normalise_dict_keys(dataset.class_to_idx)\n",
    "    idx_to_class = {v: k for k, v in dataset.class_to_idx.items()}\n",
    "    labels = list(map(lambda idx: idx_to_class[idx], labels))\n",
    "    \n",
    "    return embeddings, np.array(labels, dtype=np.str).reshape(-1, 1), dataset.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries i need for train function below\n",
    "\n",
    "def train(embeddings, labels, class_to_idx, grid_search:bool):\n",
    "    print(\"training model...\")\n",
    "    features_extractor = FaceFeaturesExtractor()\n",
    "    \n",
    "    softmax = LogisticRegression(solver='lbfgs', multi_class='multinomial', C=10, max_iter=10000, verbose=1)\n",
    "    if grid_search:\n",
    "        clf = GridSearchCV(\n",
    "            estimator=softmax,\n",
    "            param_grid={'C': [0.1, 1, 10, 100, 1000]},\n",
    "\n",
    "            cv=3\n",
    "        )\n",
    "    else:\n",
    "        clf = softmax\n",
    "    clf.fit(embeddings, labels)\n",
    "    if grid_search:\n",
    "        print(\"Best parameters set found on training set:\")\n",
    "        print(clf.best_params_)\n",
    "\n",
    "    labels = labels.tolist()\n",
    "    idx_to_class = {v: k for k, v in class_to_idx.items()}\n",
    "\n",
    "    target_names = list(map(lambda i: i[1], sorted(idx_to_class.items(), key=lambda i: i[0])))\n",
    "    report = metrics.classification_report(labels, clf.predict(embeddings), target_names=target_names, output_dict=True)\n",
    "    print(\"Training report:\")\n",
    "    print(f\"Accuracy: {report['accuracy']:.3f}\")\n",
    "    print(f\"Precision: {report['weighted avg']['precision']:.3f}\")\n",
    "    print(f\"Recall: {report['weighted avg']['recall']:.3f}\")\n",
    "    print(f\"F1-score: {report['weighted avg']['f1-score']:.3f}\")\n",
    "\n",
    "    return FaceRecogniser(features_extractor, clf, idx_to_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = os.path.join('..', 'data/01_raw/data_dev')\n",
    "test_path = os.path.join('..', 'data/01_raw/test_dev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]c:\\Users\\bilal\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\functional.py:780: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.\n",
      "  warnings.warn(\"Note that order of the arguments: ceil_mode and return_indices will change\"\n",
      "100%|██████████| 6/6 [00:03<00:00,  1.71it/s]\n",
      "C:\\Users\\bilal\\AppData\\Local\\Temp\\ipykernel_8896\\2335227457.py:48: DeprecationWarning: `np.str` is a deprecated alias for the builtin `str`. To silence this warning, use `str` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.str_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return embeddings, np.array(labels, dtype=np.str).reshape(-1, 1), dataset.class_to_idx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 512) 6\n",
      "training model...\n",
      "Training report:\n",
      "Accuracy: 1.000\n",
      "Precision: 1.000\n",
      "Recall: 1.000\n",
      "F1-score: 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bilal\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "# generate embeddings for train and test datasets\n",
    "\n",
    "train_embeddings, train_labels, train_class_to_idx = prepare_embeddings(train_path, train_path, False)\n",
    "# train model\n",
    "recogniser = train(train_embeddings, train_labels, train_class_to_idx, False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]c:\\Users\\bilal\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\functional.py:780: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.\n",
      "  warnings.warn(\"Note that order of the arguments: ceil_mode and return_indices will change\"\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 512) 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\bilal\\AppData\\Local\\Temp\\ipykernel_8896\\2335227457.py:48: DeprecationWarning: `np.str` is a deprecated alias for the builtin `str`. To silence this warning, use `str` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.str_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return embeddings, np.array(labels, dtype=np.str).reshape(-1, 1), dataset.class_to_idx\n"
     ]
    }
   ],
   "source": [
    "test_embeddings, test_labels, test_class_to_idx = prepare_embeddings(test_path, test_path, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model:FaceRecogniser, embeddings, labels, class_to_idx, grid_search:bool, augment:bool):\n",
    "    metrics_dict = {}\n",
    "\n",
    "    labels = labels.tolist()\n",
    "\n",
    "    idx_to_class = {v: k for k, v in class_to_idx.items()}\n",
    "    target_names =list(map(lambda i: i[1], sorted(idx_to_class.items(), key=lambda i: i[0])))\n",
    "    print(target_names)\n",
    "    # save the metrics to a csv file\n",
    "    gs=1 if grid_search else 0\n",
    "    ag=1 if augment else 0\n",
    "    # define metrics\n",
    "    print(labels)\n",
    "    metrics = evaluate.ModelMetrics(model)\n",
    "    report, avg_proba = metrics.calculate_metrics(embeddings, labels, target_names)\n",
    "    print(\"Test report:\")\n",
    "    print(f\"Accuracy: {report['accuracy']:.3f}\")\n",
    "    print(f\"Precision: {report['weighted avg']['precision']:.3f}\")\n",
    "    print(f\"Recall: {report['weighted avg']['recall']:.3f}\")\n",
    "    print(f\"F1-score: {report['weighted avg']['f1-score']:.3f}\")\n",
    "    print(f\"Average confidence: {avg_proba * 100}%\")\n",
    "    \n",
    "    metrics_dict = {\n",
    "        \"Accuracy\": f\"{report['accuracy']:.3f}\",\n",
    "        \"Precision\": f\"{report['weighted avg']['precision']:.3f}\",\n",
    "        \"Recall\": f\"{report['weighted avg']['recall']:.3f}\",\n",
    "        \"F1-score\": f\"{report['weighted avg']['f1-score']:.3f}\",\n",
    "        \"Average confidence\": f\"{avg_proba * 100}%\",\n",
    "        'grid_search': gs,\n",
    "        'augmentation': ag\n",
    "    }\n",
    "    \n",
    "    \n",
    "    # convert metrics to dataframe\n",
    "    metrics_df = pd.DataFrame(metrics_dict, index=[0])\n",
    "    return metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alisha_richman', 'alison_krauss', 'alison_lohman']\n",
      "[['alisha_richman'], ['alison_krauss'], ['alison_lohman']]\n",
      "['alisha_richman' 'alison_krauss' 'alison_lohman']\n",
      "[['alisha_richman'], ['alison_krauss'], ['alison_lohman']]\n",
      "Test report:\n",
      "Accuracy: 1.000\n",
      "Precision: 1.000\n",
      "Recall: 1.000\n",
      "F1-score: 1.000\n",
      "Average confidence: 16.666666666666664%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>Average confidence</th>\n",
       "      <th>grid_search</th>\n",
       "      <th>augmentation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>16.666666666666664%</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Accuracy Precision Recall F1-score   Average confidence  grid_search  \\\n",
       "0    1.000     1.000  1.000    1.000  16.666666666666664%            0   \n",
       "\n",
       "   augmentation  \n",
       "0             0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate model\n",
    "metrics_df = eval(recogniser, test_embeddings, test_labels, test_class_to_idx, False, False)\n",
    "metrics_df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10 (tags/v3.9.10:f2f3f53, Jan 17 2022, 15:14:21) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "73c768b40639084f4c4534885f66a2b010198367106e87415af0b965cb13b7d2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
